import random
from Helpers import (
    Stories,
    Fatwas as fatwa,
    TweetClient,
    Blogs as blog,
    Date as date,
    Email,
    content,
)
from datetime import datetime, timedelta

error_handler = Email.ErrorHandler()


def tweet_islamic_calendar_reminders(bot: TweetClient.TwitterBot):
    islamic_date = date.get_islamic_date()
    if islamic_date in content.islamic_events:
        try:
            event_message = content.islamic_events[islamic_date]
            tweet = (
                f"ğŸ—“ï¸ Ø­Ø¯Ø« Ø§Ù„ÙŠÙˆÙ…:\n{event_message}\n\n"
                f"ğŸŒ™ Ù„Ø§ ØªÙ†Ø³ÙˆØ§ Ø¥Ø­ÙŠØ§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ÙŠÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ± ÙˆØ§Ù„Ø¹Ù…Ù„ Ø§Ù„ØµØ§Ù„Ø­.\n"
                f"#Ø§Ù„ØªÙ‚ÙˆÙŠÙ…_Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ #Ø¥ÙŠÙ…Ø§Ù†"
            )
            bot.tweet(tweet)
        except Exception as e:
            error_handler.handle_error(f"error {e}")

    # Check if tomorrow is Monday or Thursday
    tomorrow = datetime.now() + timedelta(days=1)
    if tomorrow.weekday() == 0 or tomorrow.weekday() == 3:  # Monday = 0, Thursday = 3
        try:
            reminder_message = (
                f"ğŸŒŸ ØªØ°ÙƒÙŠØ±:\nØºØ¯Ø§Ù‹ Ù‡Ùˆ {'Ø§Ù„Ø¥Ø«Ù†ÙŠÙ†' if tomorrow.weekday() == 0 else 'Ø§Ù„Ø®Ù…ÙŠØ³'}ØŒ "
                f"ÙˆÙ‡Ùˆ Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø­Ø¨Ø¨ ÙÙŠÙ‡Ø§ Ø§Ù„ØµÙŠØ§Ù… Ø§Ù‚ØªØ¯Ø§Ø¡Ù‹ Ø¨Ø³Ù†Ø© Ø§Ù„Ù†Ø¨ÙŠ Ù…Ø­Ù…Ø¯ ï·º.\n\n"
                f"ğŸ’¡ Ø§ØºØªÙ†Ù…ÙˆØ§ Ù‡Ø°Ø§ Ø§Ù„Ø£Ø¬Ø± Ø§Ù„Ø¹Ø¸ÙŠÙ… ğŸŒ™.\n#ØµÙŠØ§Ù…_Ø³Ù†Ø© #Ø¥ÙŠÙ…Ø§Ù†"
            )
            bot.tweet(reminder_message)
        except Exception as e:
            error_handler.handle_error(f"Error while tweeting fasting reminder: {e}")


def tweet_prophetic_stories(bot: TweetClient.TwitterBot):
    base_url = "https://www.islamweb.net/ar/articles/138/Ø§Ù„Ø³ÙŠØ±Ø©-Ø§Ù„Ù†Ø¨ÙˆÙŠØ©"
    page_number = random.randint(1, 64)
    stories_url = f"{base_url}?pageno={page_number}"

    try:
        story_links = Stories.story_scraper(stories_url)
        if not story_links:
            print("No prophetic stories found to tweet.")
            return

        title, url = random.choice(story_links)
        print(f"Fetching content for story: {title}")
        summary = Stories.get_story_content(url)
        if not summary:
            print(f"Could not extract summary for {title}")
            return

        tweet = (
            f"ğŸ“œ Ù‚ØµØ© Ù…Ù† Ø§Ù„Ø³ÙŠØ±Ø©-Ø§Ù„Ù†Ø¨ÙˆÙŠØ©: {title}\n\n"
            f"ğŸ’¬ {summary}\n\n"
            f"ğŸ”— Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚ØµØ© ÙƒØ§Ù…Ù„Ø©: {url}\n\n"
            f"âœ¨ #Ø§Ù„Ø³ÙŠØ±Ø©-Ø§Ù„Ù†Ø¨ÙˆÙŠØ©# Ø¹Ø¨Ø±Ø©"
        )
        bot.tweet(tweet)

    except Exception as e:
        error_handler.handle_error(e, "Failed to scrape or tweet a prophetic story.")


def tweet_names_of_allah(bot: TweetClient.TwitterBot):

    name_info = random.choice(content.names_and_meanings)
    tweet_text = (
        f"âœ¨ Ø§Ø³Ù… Ø§Ù„Ù„Ù‡: {name_info['name']}\n\n"
        f"ğŸ“– Ù…Ø¹Ù†Ø§Ù‡: {name_info['meaning']}\n"
        f"ğŸ“Œ Ø´Ø§Ø±ÙƒÙ†Ø§ Ø§Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ ØªØ­Ø¨Ù‡ Ø£ÙƒØ«Ø± ğŸ¤.\n"
        f"#Ø£Ø³Ù…Ø§Ø¡_Ø§Ù„Ù„Ù‡_Ø§Ù„Ø­Ø³Ù†Ù‰ #Ø°ÙƒØ±"
    )

    try:
        bot.tweet(tweet_text)
    except Exception as e:
        error_handler.handle_error(f"error: {e}")


def tweet_islamic_inspirations(bot: TweetClient.TwitterBot):

    inspiration = random.choice(content.inspirations)
    try:
        bot.tweet(
            f"ğŸ’¡ {inspiration}\n\n"
            f"ğŸ¤² Ø§Ø°ÙƒØ± Ø§Ù„Ù„Ù‡ ÙˆØ§Ø³ØªÙ„Ù‡Ù… Ù…Ù†Ù‡ Ø§Ù„Ø³ÙƒÙŠÙ†Ø©.\n"
            f"#Ø¥Ù„Ù‡Ø§Ù…_Ø¥Ø³Ù„Ø§Ù…ÙŠ #Ø°ÙƒØ±_Ø§Ù„Ù„Ù‡"
        )
    except Exception as e:
        error_handler.handle_error(f"Error tweeting Islamic inspiration: {e}")


def tweet_islamic_challenges(bot: TweetClient.TwitterBot):
    challenge = random.choice(content.challenges)
    try:
        bot.tweet(
            f"ğŸ•Œ ØªØ­Ø¯ÙŠ Ø§Ù„ÙŠÙˆÙ…:\n{challenge}\n\n"
            f"ğŸ“Œ Ø¬Ø±Ø¨ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØµØºÙŠØ±Ø© Ù„ØªØ­Ø³ÙŠÙ† Ù†ÙØ³Ùƒ.\n"
            f"#ØªØ­Ø¯ÙŠ_ÙŠÙˆÙ…ÙŠ #Ø¥Ø³Ù„Ø§Ù…"
        )
    except Exception as e:
        error_handler.handle_error(f"Error tweeting Islamic challenge: {e}")


tweeted_blogs = set()
tweeted_fatwas = set()


def tweet_content(
    bot: TweetClient.TwitterBot,
    articles,
    tweeted_items,
    get_content,
    clean_content,
    tweet_format,
    max_tweets=1,
):
    tweets_sent = 0
    for title, article_url in articles:
        if tweets_sent >= max_tweets:
            break

        if article_url in tweeted_items:
            error_handler.handle_error(f"Already tweeted: {article_url}")
            continue

        content_data = get_content(article_url)
        if content_data is None:
            error_handler.handle_error(f"Could not retrieve content for {article_url}")
            continue

        cleaned_data = clean_content(content_data[0])
        tweet_text = tweet_format(title, cleaned_data, article_url)
        bot.tweet(tweet_text)
        tweeted_items.add(article_url)

        tweets_sent += 1


def fetch_and_tweet(
    url_format,
    max_pages,
    scrape_articles,
    tweeted_items,
    get_content,
    clean_content,
    tweet_format,
    max_tweets=1,
):
    try:
        for page_number in range(1, max_pages + 1):
            url = url_format.format(page_number=page_number)
            articles = scrape_articles(url)
            if not articles:
                error_handler.handle_error("No articles found.")
                return
            tweet_content(
                articles,
                tweeted_items,
                get_content,
                clean_content,
                tweet_format,
                max_tweets,
            )
            if len(tweeted_items) >= max_tweets:
                break
    except Exception as e:
        error_message = (
            f"An error occurred:\n"
            f"Last page number: {page_number}\n"
            f"Error Type: {type(e).__name__}\n"
            f"Error Message: {str(e)}\n"
        )
        error_handler.handle_error(error_message)


def extract_key_points(content, max_length=250):
    paragraphs = content.split("\n\n")
    meaningful_paragraphs = [p for p in paragraphs if len(p) > 50]

    if meaningful_paragraphs:
        main_content = meaningful_paragraphs[0]
        if len(main_content) > max_length:
            last_period = main_content[:max_length].rfind(".")
            if last_period > max_length * 0.7:
                main_content = main_content[: last_period + 1]
            else:
                main_content = main_content[:max_length] + "..."

        return main_content
    return content[:max_length] + "..."


def extract_teaser(content, max_length=150):
    if not content or len(content) < 5:
        return "Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©..."

    paragraphs = content.split("\n\n")
    meaningful_paragraphs = [p for p in paragraphs if len(p) > 20]

    if not meaningful_paragraphs:
        return content[:max_length] + "..."

    for paragraph in meaningful_paragraphs[:2]:
        sentences = paragraph.split(". ")
        for sentence in sentences:
            if "?" in sentence and len(sentence) < max_length:
                return sentence + "..."

    main_content = meaningful_paragraphs[0]

    if len(main_content) > max_length:
        cutoff_point = main_content[:max_length].rfind("ØŒ")
        if cutoff_point == -1 or cutoff_point < max_length * 0.5:
            cutoff_point = main_content[:max_length].rfind(" ")

        return main_content[:cutoff_point] + "..."

    return main_content


def get_key_themes(content, count=3):
    if not content or len(content) < 20:
        return ["Ø§Ù„ÙØªÙˆÙ‰", "Ø­ÙƒÙ…_Ø´Ø±Ø¹ÙŠ", "Ø§Ø³ØªØ´Ø§Ø±Ø©"]

    found_themes = []
    for theme in content.common_islamic_themes:
        if theme in content and len(found_themes) < count:
            found_themes.append(theme)

    if len(found_themes) < count:
        default_themes = ["Ø§Ù„ÙØªÙˆÙ‰", "Ø­ÙƒÙ…_Ø´Ø±Ø¹ÙŠ", "Ø§Ø³ØªØ´Ø§Ø±Ø©"]
        for theme in default_themes:
            if theme not in found_themes and len(found_themes) < count:
                found_themes.append(theme)

    return found_themes


def extract_fatwa_topics(title):
    topics = []

    for topic, keywords in content.topic_keywords.items():
        for keyword in keywords:
            if keyword in title and topic not in topics:
                topics.append(topic)
                break

    if not topics:
        if "Ø²ÙˆØ¬" in title or "Ø·Ù„Ø§Ù‚" in title:
            return ["Ø§Ù„Ø£Ø­ÙˆØ§Ù„_Ø§Ù„Ø´Ø®ØµÙŠØ©", "Ø§Ù„Ø£Ø³Ø±Ø©", "Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø§Øª"]
        return ["Ø§Ù„ÙØªÙˆÙ‰", "Ø­ÙƒÙ…_Ø´Ø±Ø¹ÙŠ", "Ø§Ø³ØªØ´Ø§Ø±Ø©"]

    return topics[:3]


def tweet_blogs():
    url_format = (
        "https://www.islamweb.net/ar/articles/46/Ø£Ø®Ù„Ø§Ù‚-ÙˆØªØ²ÙƒÙŠØ©?pageno={page_number}"
    )
    max_pages = 45
    fetch_and_tweet(
        url_format,
        max_pages,
        blog.scrape_articles,
        tweeted_blogs,
        blog.get_blog_content,
        blog.clean_content,
        lambda title, content, url: (
            f"ğŸ“ {title}\n\n"
            f"ğŸ’ Ù‚ÙŠÙ… Ø§Ù„Ù…Ù‚Ø§Ù„: {' | '.join(['#' + theme for theme in get_key_themes(content)])}\n\n"
            f"Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø­ÙƒÙ…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©ØŸ ğŸ‘‡\n"
            f"ğŸ“– Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø²ÙŠØ¯: {url}\n\n"
            f"ğŸ”„ Ø´Ø§Ø±Ùƒ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ø¹ Ù…Ù† ØªØ­Ø¨ ÙˆØ³Ø§Ù‡Ù… ÙÙŠ Ù†Ø´Ø± Ø§Ù„Ø¹Ù„Ù… ğŸŒŸ\n"
            f"#Ø£Ø®Ù„Ø§Ù‚ #ØªØ²ÙƒÙŠØ© #Ø¥Ø³Ù„Ø§Ù…"
        ),
        max_tweets=1,
    )


def tweet_fatwas():
    url_format = "https://www.islamweb.net/ar/fatwa/Ù…Ø®ØªØ§Ø±Ø§Øª-Ø§Ù„ÙØªÙˆÙ‰?pageno={page_number}"
    max_pages = 259
    fetch_and_tweet(
        url_format,
        max_pages,
        fatwa.scrape_articles,
        tweeted_fatwas,
        fatwa.get_fatwa_content,
        lambda data: {
            "question": (
                data[0]
                if data[0] and len(data[0]) > 5
                else f"Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ {data[0] or 'Ø­ÙƒÙ… Ø´Ø±Ø¹ÙŠ'} (Ø§Ø¶ØºØ· Ù„Ù„ØªÙØ§ØµÙŠÙ„)"
            ),
            "answer": (
                data[1]
                if data[1] and len(data[1]) > 5
                else "Ø§Ù‚Ø±Ø£ Ø§Ù„ÙØªÙˆÙ‰ ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø§Ø·Ù„Ø§Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù…Ù† Ø¹Ù„Ù…Ø§Ø¡ Ù…ÙˆØ«ÙˆÙ‚ÙŠÙ†..."
            ),
            "themes": extract_fatwa_topics(data[0] if len(data[0]) > 5 else ""),
        },
        lambda title, content, url: (
            f"ğŸ“ {title}\n\n"
            f"ğŸ“Š Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„ÙØªÙˆÙ‰: {' | '.join(['#' + theme for theme in content['themes']])}\n\n"
            f"ğŸ¤” ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø´Ø±Ø¹ÙŠ ÙƒØ§Ù…Ù„Ø§Ù‹ØŸ\n"
            f"ğŸ”— Ø§Ù‚Ø±Ø£ Ø§Ù„ÙØªÙˆÙ‰: {url}\n\n"
            f"ğŸ”„ Ø´Ø§Ø±Ùƒ Ø§Ù„ÙØªÙˆÙ‰ Ù…Ø¹ Ù…Ù† ØªØ­Ø¨ Ù„ØªØ¹Ù… Ø§Ù„ÙØ§Ø¦Ø¯Ø© ğŸŒŸ\n"
            f"#ÙØªØ§ÙˆÙ‰ #Ø¥Ø³Ù„Ø§Ù… #Ø¹Ù„Ù…"
        ),
        max_tweets=1,
    )
